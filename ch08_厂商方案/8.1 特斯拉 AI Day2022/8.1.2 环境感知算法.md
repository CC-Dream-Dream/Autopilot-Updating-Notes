### 8.1.2 环境感知算法
有关感知的介绍请参考[这里](./../../ch03_感知/), 环境感知是智能驾驶获得外部信息的源头，与大多数厂商不同的是特斯拉环境感知主要依赖视觉，而视觉存在天生缺少深度信息问题。特斯拉本次介绍了其Occupancy Networks 算法用来探索可运动3D空间, 本文接下来将对其提出的Occupancy Networks 算法进行研究分析。

#### 8.1.2.1 Occupancy Network 算法介绍

Occupancy Network 算法是特斯拉近几年一直在开发的算法，主要是通过特斯拉外部的8个摄像头视频流，去构建基于几何体积块的环绕汽车的3D空间，并持续去识别全貌即使短时间内有遮挡物，能够识别标注Occupancy的物体，例如马路牙子、汽车、行人等。此外算法还能识别物理的流动，来预测一些偶然的流体运动，如长巴士（拖挂车）的甩尾，Occupancy Network 算法可以高效识别感兴趣的点。特斯拉表示其Occupancy Network算法在算力和内存之间取得很好的效率，大概10ms就可建模完成，目前此算法已经运行在所有FSD的特斯拉上，如下图1所示。

<div align=center>

![图1. 拥堵十字路口](./imgs/8.1.2.1.gif)

</div>
<div align=center>图1. 构建环绕汽车的3D空间 </div>

#### 8.1.2.2 Occupancy Network 算法架构

<div align=center>
<img src="./imgs/8.1.2.2.jpg" width="500" height="300">
</div>
<div align=center>图2. Occupancy Network算法架构 </div>

如上图2所示，Occupancy Network算法工作流大概分以下七个步骤：

（1）Image Input
    
>8个摄像头依据摄像头标定矫正后直接输入给算法，视觉输入不使用ISP（以人为本的图像处理）同时因为摄像头的原始数据是4 位彩色它能提供16倍的动态范围给到算法，所以可以减少输入的延迟。了解摄像头基本原理点击《智能汽车要用多少个摄像头？分别干啥？什么原理？》。

（2） Image Featurizers
   
>使用预训练的深度神经网络模型对图像进行特征化,输入给下一步。特斯拉采用RegNet 以及BiFPNs算法来特征化图像，特征化基本就是识别物体了。

（3）Spatial Attention

  是卷积神经网络中用于空间注意的模块。它利用特征的空间间关系生成空间注意力图，也就是构建空间信息。这里特斯拉提到两个算法Mlticam Qurey Emdedding 也就是多摄像头查询，Spatial Query空间查询然后输入给注意力Attention算法，这里就是构建空间。
   
（4）Temporal Alignment

  分为两个部分，一个部分是自己车辆的轨迹对齐，另外一个将各个识别特征物对齐，初步形成了时空特征。

（5）Deconvolutions

  去卷积也就是把浓缩的特征反向成物体。这里其中有一个一直是普通视觉算法的噩梦，就是路面地理信息，例如上下坡度，特斯拉表示其算法能够识别路面的地理特征。

（6）Volume Outputs

  去卷积之后的反向物体，将从空间上能代表物体大小，被放置在时空中，而且此类空间占据还根据路面的情况自动匹配,这里特斯拉讲到一个算法NeRF state，能够表示具有复杂遮挡的详细场景几何，这样可以让时空更加真实。


（7）Queryable Outputs

  这里很有意思，去卷积之后的反向物体有些可能不能完全代表真实的物体的大小，所以特斯拉算法采用查询法去数据库中查询真实世界的结果，进行位置和大小的矫正再进行空间放置。


Occupancy Networks 算法可以通过摄像头收割数据，然后利用NeRFs算法构建真实世界的精准映射-虚拟世界，当然特斯拉当前的虚拟构建显然做不到把摄像头色彩完全投影进来，特斯拉目前主要任务是通过车辆收集数据构建可支持自动驾驶所需关键信息的虚拟3D世界，特斯拉也想收割全球以及其各种天气下的信息，当然这当中肯定还有很多技术问题有待解决，所以特斯拉也趁机人才招募广播一把。